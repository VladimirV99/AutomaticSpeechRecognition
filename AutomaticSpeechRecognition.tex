% !TEX encoding = UTF-8 Unicode
\documentclass[a4paper]{article}

\usepackage{color}
\usepackage{url}
\usepackage[T2A]{fontenc} % enable Cyrillic fonts
\usepackage[utf8]{inputenc} % make weird characters work
\usepackage{graphicx}
\graphicspath{ {images/} }

\usepackage[english,serbian]{babel}
%\usepackage[english,serbianc]{babel} %ukljuciti babel sa ovim opcijama, umesto gornjim, ukoliko se koristi cirilica

\usepackage[unicode]{hyperref}
\hypersetup{colorlinks,citecolor=green,filecolor=green,linkcolor=blue,urlcolor=blue}

\usepackage{listings}

\usepackage{amsmath}
\usepackage{amsfonts}

% https://tex.stackexchange.com/questions/5223/command-for-argmin-or-argmax
\DeclareMathOperator*{\argmax}{argmax}

%\newtheorem{primer}{Пример}[section] %ćirilični primer
\newtheorem{primer}{Primer}[section]

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ 
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
  basicstyle=\scriptsize\ttfamily,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  firstnumber=1000,                % start line enumeration with line 1000
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Python,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\begin{document}

\title{Automatsko prepoznavanje govora\\ \small{Seminarski rad u okviru kursa\\Metodologija stručnog i naučnog rada\\Matematički fakultet}}

\author{Vladimir Vuksanović, Aleksa Kojadinović, Lazar Čeliković\\kontakt email prvog, drugog, trećeg autora}

%\date{9.~april 2015.}

\maketitle

\abstract{
U ovom tekstu je ukratko prikazana osnovna forma seminarskog rada. Obratite pažnju da je pored ove .pdf datoteke, u prilogu i odgovarajuća .tex datoteka, kao i .bib datoteka korišćena za generisanje literature. Na prvoj strani seminarskog rada su naslov, apstrakt i sadržaj, i to sve mora da stane na prvu stranu! Kako bi Vaš seminarski zadovoljio standarde i očekivanja, koristite uputstva i materijale sa predavanja na temu pisanja seminarskih radova. Ovo je samo šablon koji se odnosi na fizički izgled seminarskog rada (šablon koji \emph{morate} da koristite!) kao i par tehničkih pomoćnih uputstava. Pročitajte tekst pažljivo jer on sadrži i važne informacije vezane za zahteve obima i karakteristika seminarskog rada.}
% Tema ovog rada je da priblizi citaoca zadatku automatskog prepoznavanja govora, problemima koji se javljaju i najznacajnijim arhitekturama ovih sistema.

\bigskip
\textbf{Ključne reči:} prepoznavanje govora

\tableofcontents

\newpage

\section{Uvod}
\label{sec:uvod}

Govor je za ljude najintuitivniji i prirodniji nacin komunikacije. Zbog toga je od samog nastanka kompjutera, nastala i ideja da koristimo isti nacin komunikacije da interagujemo sa njima.
To bi znatno smanjilo potrebno predznanje za koriscenje kompjutera i ucnilio ga pristupacnijim vecem broju ljudi. Najveca prepreka ovim sistemima do skoro je bio kako sa velikom tacnosti prepoznati sta je korisnik rekao.
Taj postupak se naziva automatsko prepoznavanje govora.

\textbf{Automatsko prepoznavanje govora} (eng.~{\em Automatic Speech Recognition, ASR}) je proces pretvaranja zvučnog signala govora u sekvencu reči pomoću kompjutera.
Neke od najznacajnijih primena ovih sistema su: pametni licni asistenti (Google Assistant\footnote{https://assistant.google.com/}, Apple Siri\footnote{https://www.apple.com/siri/},\dots), transkripcija snimaka, pretrazivanje audio sadrzaja i pristupacnost.
% slika waveform u recenicu (Uday 8.1) ?

Iako su istrazivanja na ovu temu pocela jos sredinom dvadesetog veka, popularnost je pocela da dobija tek u poslednjoj deceniji kada je uvodjenje dubokih neuronskih mreza drasticno povecalo performanse ovih sistema.
Ta razlika je bila dovoljna da ucini ove sisteme prakticno primenljivim umesto nezgodnim za upotrebu zbog velikog broja gresaka.
Jedan od najznacajnijih postignuca je ostvareno 2016. godine je kompanija Majkrosoft napravila sistem koji je ostvario iste rezultate kao ljudski eksperti na transkripciji Switchboard skupa podataka \cite{switchboard}.
% Human level switchboard
% https://blogs.microsoft.com/ai/historic-achievement-microsoft-researchers-reach-human-parity-conversational-speech-recognition/
% https://www.microsoft.com/en-us/research/blog/microsoft-researchers-achieve-new-conversational-speech-recognition-milestone/
Za glavne uzroke ovog naglog poboljsanja se smatraju \cite{hannun2021history}:
\begin{enumerate}
  \item Sakupljanje velike kolicine tanskribovanih skupova podataka
  \item Nagli porast u performansama grafickih procesorskih jedinica (GPU)
  \item Poboljsanje algoritama za ucenje i arhitektura modela
\end{enumerate}
% The History of Speech Recognition to the Year 2030
% 1) the curation of massive transcribed data sets,
% 2) the rapid rate of progress in graphics processing units
% 3) the improvement in the learning algorithms and model architectures.

% izlistati poglavlja
U nastavku cemo prvo navesti neke izazove koje treba da resimo da bi smo napravili dobar sistem za prepoznavanje govora, zatim cemo opisati nacin rada dva najpopularnija modela: statisticki i end-to-end i na kraju cemo predstaviti nacin za njihovu evaluaciju.

\section{Izazovi}
% https://www.youtube.com/watch?v=q67z7PTGRi8
Prepoznavanje govora je veoma tezak zadatak zato sto je potrebno da radi podjednako dobro u veoma razlicitim uslovima.
Neki od najvecih izazova su:
\begin{itemize}
  \item \textbf{Mala kolicina podataka za trening} --- 
  Za ostvarivanje dobrih rezultata potrebno je sakupiti vise stotina ili cak hiljada sati labeliranih zvucnih snimaka koji treba da sadrze vise govornika razlicitog pola i starosti, koji govore razlicitim akcentima. 
  Dok u skorije vreme jeste nastao porast u kolicini dostupnih podataka, veliki problem jos uvek predstavlja reprezentativnost razlicitih varijacija u govoru i nedostatak podataka za jezike sa manjim brojem govornika. 
  Zbog toga se istrazuju alternativni nacini za treniranje kao sto su samo-treniranje (eng.~{\em self-training}) \cite{baevski2020wav2vec}, iterativno treniranje \cite{park2020noisy} ili treniranje koristeci kompjuterski generisan glas \cite{hannun2014deep}. 
  U dodatku \ref{sec:skupovi} se moze naci tabela sa pregledom nekih od najpopularnijih trening skupova na engleskom jeziku.
  
  \item \textbf{Stil govora} --- 
  Postoje razliciti sistemi u zavisnosti od toga koji tip govora mogu da prepoznaju \cite{anusuya2010speech}. Tipovi govora poredjani po tezini propoznavanja su: 
  \begin{enumerate}
    \item Izolovane reci --- reci su razdvojene dugim periodima tisine
    \item Povezane reci --- reci su razdvojene kratkim pauzama
    \item Neprekidan govor --- uvezbani govor, citanje ili diktiranje
    \item Spontan govor --- neuvezbani, prirodni govor 
  \end{enumerate}
  Prve implementacije prepoznavanja govora su radile na nivou izolovanih reci i koristile su se za prepoznavanje odredjenih komandi ili cifara.
  Danas se najvise truda ulaze u poboljsanje neprekidnog i spontanog govora.

  \item \textbf{Karakteristike govornika} ---
  Svaki covek ima razlicitu boju glasa i govori razlicitom brzinom. Cak i starost osobe i jacina govora bitno uticu na frekvenciju glasa.
  Poseban problem pravi postojanje razlicitih dijalekata i akcenata koji mogu da imaju potpuno razlicite nacine za izgovaranje istih reci.
  Jedan nacin za resavanje ovog problema je treniranje sistema na glasu govornika koji ce ga koristiti.
  To su sistemi zavisni od korisnika (eng.~{\em speaker dependent}) i koriste se u slucajevima da samo jedno osoba treba da ih koristi.
  Sa druge strane postoje sistemi nezavisni od korisnika (eng.~{\em speaker independent}) koji treba da rade podjednako dobro za sve govornike.
  
  \item \textbf{Okruzenje govornika} --- 
  Ovi sistemi ce retko biti korisceni u potpuno tihim prostorijama sa profesionalnom opremom za snimanje, zbog toga treba da budu tolerantni na razlicite vrste pozadinske buke ili kvaliteta mikrofona (koliko je to moguce). 
  Neke vrste sumova je moguce otkloniti analizom zvuka ili naprednijim metodama \cite{xu2015enhancement}, ali jedan od najvecih problema predstavlja postojanje drugih govornika u okolini.
  Te signale je cesto tesko razlikovati od glasa primarnig govornika, i samim tim tesko ukloniti.
  
  \item \textbf{Velicina recnika} --- 
  Povecanje broja reci koje model moze da prepozna takodje povecava njegovu slozenost i otezava treniranje, ali se time dobija na tacnosti. 
  Zbog toga je potrebno naci dobar kompromis izmedju velicine recnika i slozenosti modela. 
  U slucajevima kada je potrebno pouzdano prepoznati samo neki skup komandi koriste se mali recnici i oni su cesto veoma pouzdani, ali za prepoznavanje opsteg govora danasnji sistemi su trenirani na skupu od oko 50.000-100.000 reci.
\end{itemize}

\section{Statisticki model}
% Uday knjiga chap. 8
Dugo vremena statisticki pristup je bio dominantan za sisteme za prepoznavanje govora.
Cilj ovih sistema je da pronadju najverovatniju transkripciju za zadati signal.
% Large Vocabulary Continuous Speech Recognition a Review
Formalno, neka je $\hat{W}$ optimalan niz reci za transkripciju nekog zvucnog signala $X$. Cilj je optimizovati formulu \cite{kamath2019nlp}:
\begin{equation*}
  \hat{W} = \argmax_{W} P(W|X)
\end{equation*}
primenom Bajesove formule to mozemo da zapisemo kao:
\begin{equation*}
  \hat{W} = \argmax_{W} \frac{P(X|W) P(W)}{P(X)}
\end{equation*}
a kako je $P(X)$ konstantno za konkretan ulaz, mozemo da ga eliminisemo:
\begin{equation*}
  \hat{W} = \argmax_{W} P(X|W) P(W)
\end{equation*}
Prvi deo, $P(X|W)$, racuna akusticki model, a drugi, $P(W)$, racuna jezicki model.
Ideja je da odvojeno optimizujemo obe prethodne velicine i ocekujemo da ce se tako maksimizirati ukupna verovatnoca.
U praksi, $P(X|W)$ je tesko precizno odrediti na nivou reci zbog velikih varijacija u izgovoru, pa se cesce odredjuje na nivou glasova ili fonema.
Zbog toga se dodatno uvodi i model izgovora (eng.) koji kombinuje te manje jedinice u reci. 

% slika modela
% https://www.idiap.ch/software/bob/docs/bob/bob.kaldi/stable/_images/ASR.png
Na slici \ref{fig:statistical_model} je prikazana cela struktura statistickog modela od zvucnog signala do transkripcije:
\begin{figure}[h!]
  \begin{center}
    \includegraphics[scale=0.4]{statistical_model.png}
  \end{center}
  \caption{Statisticki model}
  \label{fig:statistical_model}
\end{figure}
U nastavku ce biti opisana svaka od pomenutih komponenti, njena uloga i nacin rada.

\subsection{Procesiranje zvucnog signala}
Sirovi zvucni signal je veoma nepogodan za koriscenje zato sto sadrzi veliku kolicinu nepotrebnih informacija i šuma.
Zbog toga se pre prosledjivanja akustickom modelu, signal prvo obradjuje tako da ostanu samo kljucne karakteristike i smanji sum i velicina reprezentacije.

Signal delimo na kratke segmente koje zovemo okviri (eng. frame).
Svaki od njih je fiksne duzine (obicno 10-30 milisekundi) sa kratkim preklapanjem susednim okvirima radi smanjenja naglih promena prilikom prelaska iz jednog u drugi.
Pretpostavka je da je u svakom od okviru glas konstantan, to jest da se glasovi mogu menjati samo prelaskom iz jednog okvira u drugi.
Na svaki od tih novodobijenih delova se zatim primenjuje neka vrsta spektralne analize kojom se izdvajaju samo njegove najbitnije karakteristike.
Tacna reprezentacija koja se koristi varira u zavisnosti od modela, ali jedna od najpopularnijih je MFCC [?].

\subsection{Akusticki model}
% https://www.cs.cmu.edu/~roni/10601-slides/hmm-for-asr-whw.pdf
% https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-345-automatic-speech-recognition-spring-2003/lecture-notes/lecture15.pdf
% prepoznavanje fonema
Akusticki model je zaduzen da pretvori sekvencu okvira u sekvencu fonema. % objasniti foneme
Za modelovanje svake foneme se koriste skriveni Markovljevi modeli (eng.~{\em Hidden Markov Models}) \cite{rabiner1989hmm}.
Ti modeli se zatim nadovezuju da grade slova, reci...
% model se trenira Baum-Welch algorithm or Viterbi training algorithm
% dinamicko programiranje

\subsection{Model izgovora}
U slucaju da zelimo da prepoznajemo samo malu kolicinu reci, prethodni model bi bio sasvim dovoljan pod uslovom da imamo dobar trening skup za te reci.
Problem nastaje ako zelimo da prepoznamo vecu kolicinu reci, tada cemo za neku rec imati mozda samo par primera u celom skupu.
To nije dovoljno da se istrenira model. 
\begin{equation*}
  P(X|W) = P(X|Q) \sum_{Q} P(Q|W)
\end{equation*}
$P(Q|W)$ zovemo model izgovora (eng.~{\em Pronunciation Model}).
On mapira niz fonema u odgovarajucu rec ili niz slova koja se tako izgovara.
% ovo definisu eksperti za tu oblast
% CMUdict ~150_000 reci

\subsection{Jezicki model}
% sintaksicka i semanticka provera
% primer
Odredjuje najverovatniju kombinaciju reci
% n-gram model

\subsection{Dekodiranje}
U praksi je recnik prilicno veliki pa nije prakticno racunati verovatnocu za svaku kombinaciju reci u recenici.
Umesto toga se koristi beam search algoritam.

\section{End-to-end model}
% prednosti u odnosu na HMM
% nije potreban ekspert za jezik
% lakse treniranje
% mogu sami da zakljuce bolju reprezentaciju od MFCC (npr pomocu CNN)

% mane u ondosu na HMM
% vice broj podataka

% modeli zasnovani na paznji i CTC modeli
\subsection{CTC model}

Neka je ulazni zvuk uzorkovan u proizvoljnom broju jednakih vremenskih intervala,  gde je svaki od njih predstavljen vektorom realnih brojeva duzine $m$.  Neka je $L$ konacna azbuka labela (oznaka).  Cilj je napraviti preslikavanje $h$ koje slika proizvoljan zvucni signal u niz labela:

\begin{equation}
\label{eq:pres1}
h: (\mathbb{R}^m)^* \rightarrow L^* 
\end{equation}


U praksi fiksiramo broj vremenskih trenutaka na neku vrednost $T$.  Iako je broj trenutaka fiksiran za zvucne signale,  nizovi labela ne moraju biti iste duzine za svaku ulaznu instancu, stoga jednu trening instancu predstavlja par $(\textbf{x}, \textbf{z})$ gde je $z$ vektor labela duzine najvise $T$.  Ako bismo test skup oznacili sa O, tada funkciju greske mozemo definisati na sledeci nacin:


\begin{equation}
\label{eq:LER}
LER(h, O) = \frac{1}{|O|}\sum_{(\textbf{x}, \textbf{z}) \in O}\frac{ED(h(\textbf{x}), \textbf{z})}{\textbf{|z|}}
\end{equation}


$ED$ predstavlja edit distancu (minimalni broj izmena koji dovodi jedan niz karaktera do drugog, pri cemu dozvoljene izmene podrazumevaju brisanje,  supstituciju i umetanje karaktera).  Prethodna mera naziva se stopa greske labela (\textit{eng.  label error rate - LER}).  


Formula \ref{eq:LER} jeste prirodna ocena greske za probleme koji za cilj imaju minimizaciju greske prevodjenja.

\bigskip
Koristeci sva prethodna razmatranja konstruisemo rekurentnu neuronsku mrezu koja na ulazu ima $mT$ ulaza,  dok se na izlazu dobija $T$ vektora dimenzija $L' = L \cup \{\epsilon\}$ pri cemu svaki predstavlja raspodelu verovatnoca oznaka za svaki trenutak prosirujuci azbuku blanko labelom $\epsilon$.

\bigskip
Neformalno receno,  prolaskom kroz izlazne softmax nizove dobijamo putanju $\pi \in (L')^T$ koja predstavlja jedan moguci odabir labela.  Ako $y_{\pi_t}^t$ predstavlja softmax ???? vrednost $t$-tog trenutka oznake $\pi_t$ tada verovatnocu odabira kompletne putanje dobijamo kao proizvod:

$$p(\pi|x) = \prod_{t=1}^Ty_{\pi_t}^t$$

U praksi uzorkovanje zvuka se vrsi u veoma sitnim vremenskim intervalima (oko 10ms). Stoga je pojava blanko ili dupliciranih oznaka veoma cesta.  Iz tog razloga uvodimo preslikavanje $\beta$ cija je uloga preciscavanje nizova labela uklanjanjem blanko oznaka i susednih duplikata.  

$$\beta : (L')^T \rightarrow L^U,  U \leq T$$

Primetimo da za jednu preciscenu putanju $l$ moze postojati vise mogucih izvornih putanja,  pa je verovatnoca njenog odabira jednaka sumi po svim izvornim putanjama.

\begin{equation}
\label{eq:beta}
p(l | x) = \sum_{\pi \in \beta^{-1}(l)} p(\pi | x)
\end{equation}

Imajuci u vidu sve prethodno navedeno,  zadatak preslikavanja $h$ je odabir najverovatnije preciscene putanje za dati ulaz.

\begin{equation}
\label{eq:h_x}
h(x) = \argmax_{l \in L^U} p(l | x)
\end{equation}

Najjednostavniji algoritam jeste pohlepni odabir najbolje oznake za svaki vremenski trenutak ponaosob.  Medjutim, ovakav pristup ne garantuje optimalnost.  Naravno,  postoje bolji algoritmi za resavanje datog problema. Isti nece biti obradjivani u ovom radu, ali se mogu naci u [].

\subsection{modeli zasnovani na paznji}

\section{Metrike za evaluaciju}
Standardna mera za procenu kvaliteta sistema za prepoznavanje govora je stopa pogresnih reci (eng.~{\em Word Error Rate (WER)}).
% https://en.wikipedia.org/wiki/Word_error_rate
\begin{equation*}
  WER = \frac{S + D + I}{N}
\end{equation*}
gde je $S$ broj zamenjenih reci, $D$ broj obrisanih reci, $I$ broj umetnutih reci, i $N$ ukupan broj reci u referentnoj recenici.
Minimalna vrednost koju moze da dobije je 0, dok maksimalna vrednost moze da bude preko 1 (npr. veliki broj umetnutih reci).
% dinamicko programiranje
% Wagner-Fischer algorithm
Stopa pogresnih reci se efikasno racuna dinamickim programiranjem, pomocu Vagner-Fiserovog algoritma (eng.)

Cilj sistema za prepoznavanje govora je da minimizuje ovu vrednost.

\section{Zaključak}
\label{sec:zakljucak}

% \section{Osnovna uputstva}
% Vaš seminarski rad mora da sadrži najmanje jednu \textbf{sliku}, najmanje jednu \textbf{tabelu} i najmanje \textbf{sedam referenci} u spisku literature. Najmanje jedna slika treba da bude originalna i da predstavlja neke podatke koje ste Vi osmislili da treba da prezentujete u svom radu. Isto važi i za najmanje jednu tabelu. 	Od referenci, neophodno je imati bar jednu \textbf{knjigu}, bar jedan \textbf{naučni članak} iz odgovarajućeg časopisa i bar jednu adekvatnu \textbf{veb adresu}. 
% \textbf{Dužina seminarskog rada treba da bude od 10 do 12 strana.} Svako prekoračenje ili potkoračenje biće kažnjeno sa odgovarajućim brojem poena. Eventualno, nakon strane 12, može se javiti samo tekst poglavlja \textbf{Dodatak} koji sadrži nekakav dodatni k\^{o}d, ali je svakako potrebno da rad može da se pročita i razume i bez čitanja tog dodatka. 

% \section{Engleski termini i citiranje}	
% \label{sec:termini_i_citiranje}

% Na svakom mestu u tekstu naglasiti odakle tačno potiču informacije. Uz sve novouvedene termine u zagradi naglasiti od koje engleske reči termin potiče. 

% Naredni primeri ilustruju način uvođenja enlegskih termina kao i citiranje.

% \begin{primer}
% Problem zaustavljanja (eng.~{\em halting problem}) je neodlučiv \cite{haltingproblem}.
% \end{primer}

% \begin{primer}
% Za prevođenje programa napisanih u programskom jeziku C može se koristiti GCC kompajler \cite{gcc}.
% \end{primer}

% \begin{primer}
%  Da bi se ispitivala ispravost softvera, najpre je potrebno precizno definisati njegovo ponašanje \cite{laski2009software}. 
% \end{primer}

% Broj naslova i podnaslova je proizvoljan. Neophodni su samo Uvod i Zaključak. Na poglavlja unutar teksta referisati se po potrebi. 
% \begin{primer}
% U odeljku \ref{sec:naslov1} precizirani su osnovni pojmovi, dok su zaključci dati u odeljku \ref{sec:zakljucak}.
% \end{primer}

\addcontentsline{toc}{section}{Literatura}
\appendix
\bibliography{seminarski} 
% \bibliographystyle{plain}
\bibliographystyle{ieeetr}

\appendix

% dodatak: pregled skupa podataka za trening
% https://github.com/double22a/speech_dataset
% CommonVoice - https://commonvoice.mozilla.org/en/datasets
% TIMIT - https://catalog.ldc.upenn.edu/LDC93S1
% LibriSpeech - https://openslr.org/12/
\section{Pregled skupova podataka}
\label{sec:skupovi}

\begin{tabular}{|c|c|c|}
  \hline
  TIMIT & cell2 & cell3 \\ 
  SwitchBoard & cell5 & cell6 \\ 
  LibriSpeech & cell8 & cell9 \\ 
  CommonVoice & a & a \\
  \hline
\end{tabular}

% \begin{table}[h!]
% \begin{center}
% \caption{Razlčita poravnanja u okviru iste tabele ne treba koristiti jer su nepregledna.}
% \begin{tabular}{|c|l|r|} \hline
% centralno poravnanje& levo poravnanje& desno poravnanje\\ \hline
% a &b&c\\ \hline
% d &e&f\\ \hline
% \end{tabular}
% \label{tab:tabela1}
% \end{center}
% \end{table}


\end{document}

